# Spring AI Alibaba RAG ä¼˜åŒ–å®æ–½è·¯çº¿å›¾

> **æ–‡æ¡£ç‰ˆæœ¬**: v1.0
> **åˆ›å»ºæ—¥æœŸ**: 2026-01-04
> **é€‚ç”¨ç‰ˆæœ¬**: Spring AI 1.1.0 + Spring AI Alibaba 1.1.0.0-RC2

---

## ğŸ“‹ ç›®å½•

- [é¡¹ç›®èƒŒæ™¯](#é¡¹ç›®èƒŒæ™¯)
- [å½“å‰ RAG å®ç°åˆ†æ](#å½“å‰-rag-å®ç°åˆ†æ)
- [Phase 1: Level 1 åŸºç¡€ä¼˜åŒ–](#phase-1-level-1-åŸºç¡€ä¼˜åŒ–)
- [Phase 2: Level 2 è¿›é˜¶ä¼˜åŒ–](#phase-2-level-2-è¿›é˜¶ä¼˜åŒ–)
- [å®æ–½æ—¶é—´è¡¨](#å®æ–½æ—¶é—´è¡¨)
- [é…ç½®å˜æ›´](#é…ç½®å˜æ›´)
- [é¢„æœŸæ”¶ç›Š](#é¢„æœŸæ”¶ç›Š)
- [éªŒæ”¶æ ‡å‡†](#éªŒæ”¶æ ‡å‡†)
- [é£é™©ä¸æ³¨æ„äº‹é¡¹](#é£é™©ä¸æ³¨æ„äº‹é¡¹)
- [ä¸‹ä¸€æ­¥è¡ŒåŠ¨](#ä¸‹ä¸€æ­¥è¡ŒåŠ¨)

---

## é¡¹ç›®èƒŒæ™¯

å½“å‰é¡¹ç›®æ˜¯ä¸€ä¸ªåŸºäº Spring AI Alibaba çš„æ™ºèƒ½å¯¹è¯ç³»ç»Ÿï¼Œæ”¯æŒ RAGï¼ˆæ£€ç´¢å¢å¼ºç”Ÿæˆï¼‰åŠŸèƒ½ã€‚è™½ç„¶åŸºç¡€åŠŸèƒ½å·²å®ç°ï¼Œä½†åœ¨æ–‡æ¡£ç®¡ç†ã€æ£€ç´¢å‡†ç¡®æ€§ã€æŸ¥è¯¢ä¼˜åŒ–ç­‰æ–¹é¢è¿˜æœ‰è¾ƒå¤§æå‡ç©ºé—´ã€‚

### æŠ€æœ¯æ ˆ

- **åç«¯æ¡†æ¶**: Spring Boot 3.5.6
- **AI æ¡†æ¶**: Spring AI 1.1.0
- **Alibaba AI**: Spring AI Alibaba 1.1.0.0-RC2
- **å‘é‡æ•°æ®åº“**: Redis Stack
- **Embedding æ¨¡å‹**: æ™ºè°± AI Embedding-3 (1024ç»´)
- **å¯¹è¯æ¨¡å‹**: DeepSeek / é€šä¹‰åƒé—® / æ™ºè°± AI

---

## å½“å‰ RAG å®ç°åˆ†æ

### ç°æœ‰é…ç½®

```java
// ChatClientConfiguration.java:80-87
@Bean
public VectorStoreDocumentRetriever vectorStoreDocumentRetriever(VectorStore vectorStore) {
    return VectorStoreDocumentRetriever.builder()
        .topK(3)                        // å›ºå®šè¿”å›3ä¸ªæ–‡æ¡£
        .vectorStore(vectorStore)
        .similarityThreshold(0.8)       // å›ºå®šé˜ˆå€¼0.8
        .build();
}

// ChatClientConfiguration.java:93-101
@Bean
public RetrievalAugmentationAdvisor retrievalAugmentationAdvisor(
        VectorStoreDocumentRetriever retriever) {
    return RetrievalAugmentationAdvisor.builder()
        .documentRetriever(retriever)
        .queryAugmenter(ContextualQueryAugmenter.builder()
            .allowEmptyContext(true)    // å…è®¸ç©ºä¸Šä¸‹æ–‡ï¼ˆé¿å…MCPå†²çªï¼‰
            .build())
        .build();
}
```

### 10 å¤§å±€é™æ€§

| # | é—®é¢˜ | å½±å“ |
|---|------|------|
| 1 | **æ–‡æ¡£æ— å…ƒæ•°æ®** | æ— æ³•è¿½æº¯æ¥æºã€æ—¶é—´æˆ³ã€åˆ†ç±»ç­‰ä¿¡æ¯ |
| 2 | **ç¼ºå°‘æ–‡æ¡£åˆ†å—** | é•¿æ–‡æ¡£å¤„ç†ä¸ä½³ï¼Œè¶…å‡ºä¸Šä¸‹æ–‡çª—å£ |
| 3 | **æ£€ç´¢ç­–ç•¥å•ä¸€** | ä»…åŸºäºå‘é‡ç›¸ä¼¼åº¦ï¼Œå‡†ç¡®ç‡æœ‰é™ |
| 4 | **é™æ€é…ç½®å‚æ•°** | topK å’Œé˜ˆå€¼ç¡¬ç¼–ç ï¼Œæ— æ³•åŠ¨æ€è°ƒæ•´ |
| 5 | **æ— é‡æ’åº** | æ£€ç´¢ç»“æœæ²¡æœ‰äºŒæ¬¡ä¼˜åŒ– |
| 6 | **ç¼ºå°‘å¼•ç”¨æ¥æº** | ç”¨æˆ·æ— æ³•éªŒè¯ç­”æ¡ˆå‡†ç¡®æ€§ |
| 7 | **æ— æ–‡æ¡£ç®¡ç†** | åªèƒ½æ·»åŠ ï¼Œä¸èƒ½æ›´æ–°/åˆ é™¤ |
| 8 | **æ— æŸ¥è¯¢ä¼˜åŒ–** | æ²¡æœ‰æŸ¥è¯¢é‡å†™å’Œæ‰©å±• |
| 9 | **æ— æ•ˆæœè¯„ä¼°** | æ— æ³•é‡åŒ– RAG è´¨é‡ |
| 10 | **æ— æ–‡æ¡£é¢„å¤„ç†** | æ²¡æœ‰å»é‡ã€æ¸…æ´—ã€æ ‡å‡†åŒ– |

### å½“å‰æŒ‡æ ‡

- **æ£€ç´¢å‡†ç¡®ç‡**: ~65%
- **æ£€ç´¢å¬å›ç‡**: ~60%
- **å“åº”ç›¸å…³æ€§**: ~70%
- **å¹³å‡å“åº”æ—¶é—´**: 1.2s

---

## Phase 1: Level 1 åŸºç¡€ä¼˜åŒ–

**ç›®æ ‡**: RAG åŸºç¡€èƒ½åŠ›ä» 60 åˆ†æå‡åˆ° 75 åˆ†
**é¢„è®¡æ—¶é—´**: 3-4 å¤©

---

### ä»»åŠ¡ 1.1: æ·»åŠ æ–‡æ¡£å…ƒæ•°æ®æ”¯æŒ

**é¢„è®¡å·¥ä½œé‡**: 0.5 å¤©

#### ç›®æ ‡

ä¸ºæ‰€æœ‰æ–‡æ¡£æ·»åŠ å®Œæ•´çš„å…ƒæ•°æ®ï¼Œæ”¯æŒè¿‡æ»¤å’Œè¿½æº¯ã€‚

#### å®æ–½æ­¥éª¤

1. **åˆ›å»ºæ–‡æ¡£å…ƒæ•°æ®æ ‡å‡†ç±»**

åˆ›å»º `com.xurx.springai.model.DocumentMetadata.java`:

```java
package com.xurx.springai.model;

import lombok.Builder;
import lombok.Data;
import java.time.Instant;
import java.util.HashMap;
import java.util.Map;

@Data
@Builder
public class DocumentMetadata {
    private String docId;           // æ–‡æ¡£å”¯ä¸€ID
    private String source;          // æ¥æºï¼ˆå¦‚ "manual_import", "QA.csv"ï¼‰
    private String docType;         // æ–‡æ¡£ç±»å‹ï¼ˆå¦‚ "qa_pair", "article", "manual"ï¼‰
    private String category;        // åˆ†ç±»ï¼ˆå¦‚ "menu", "tech_doc"ï¼‰
    private String timestamp;       // å¯¼å…¥æ—¶é—´æˆ³
    private String contentHash;     // å†…å®¹å“ˆå¸Œï¼ˆç”¨äºå»é‡ï¼‰
    private Integer charCount;      // å­—ç¬¦æ•°

    public Map<String, Object> toMap() {
        Map<String, Object> map = new HashMap<>();
        map.put("doc_id", docId);
        map.put("source", source);
        map.put("doc_type", docType);
        map.put("category", category);
        map.put("timestamp", timestamp);
        map.put("content_hash", contentHash);
        map.put("char_count", charCount);
        return map;
    }
}
```

2. **æ”¹é€  RagController.importData**

ä¿®æ”¹ `com.xurx.springai.controller.RagController.java`:

```java
@PostMapping("/importData")
public String importData(@RequestParam String data,
                          @RequestParam(required = false, defaultValue = "manual_import") String source,
                          @RequestParam(required = false) String category,
                          @RequestParam(required = false, defaultValue = "text") String docType) {

    // æ•°æ®æ¸…æ´—
    String cleanedData = data.trim()
        .replaceAll("\\s+", " ")
        .replaceAll("[\\x00-\\x08\\x0B\\x0C\\x0E-\\x1F]", "");

    // è®¡ç®—å†…å®¹å“ˆå¸Œ
    String contentHash = DigestUtils.md5Hex(cleanedData);

    // æ„å»ºå…ƒæ•°æ®
    DocumentMetadata metadata = DocumentMetadata.builder()
        .docId(UUID.randomUUID().toString())
        .source(source)
        .docType(docType)
        .category(category)
        .timestamp(Instant.now().toString())
        .contentHash(contentHash)
        .charCount(cleanedData.length())
        .build();

    // æ„å»ºæ–‡æ¡£
    Document document = new Document(cleanedData, metadata.toMap());
    vectorStore.add(List.of(document));

    return "Data imported with metadata successfully: " + metadata.getDocId();
}
```

3. **æ”¹é€  MenuController.importData**

ä¿®æ”¹ `com.xurx.springai.controller.MenuController.java`:

```java
@PostMapping("/importData")
public String importData() {
    try {
        ClassPathResource resource = new ClassPathResource("QA.csv");
        InputStreamReader reader = new InputStreamReader(resource.getInputStream(), "UTF-8");

        CSVParser csvParser = CSVFormat.DEFAULT.builder()
            .setHeader()
            .setSkipHeaderRecord(true)
            .setIgnoreSurroundingSpaces(true)
            .setTrim(true)
            .build()
            .parse(reader);

        List<Document> documents = new ArrayList<>();
        int index = 0;

        for (CSVRecord record : csvParser) {
            String question = record.get(0);
            String answer = record.get(1);
            String content = "é—®é¢˜ï¼š" + question + "\nå›ç­”ï¼š" + answer;

            // æ„å»ºå…ƒæ•°æ®
            DocumentMetadata metadata = DocumentMetadata.builder()
                .docId(UUID.randomUUID().toString())
                .source("QA.csv")
                .docType("qa_pair")
                .category("menu")
                .timestamp(Instant.now().toString())
                .contentHash(DigestUtils.md5Hex(content))
                .charCount(content.length())
                .build();

            // æ·»åŠ é¢å¤–çš„ä¸šåŠ¡å­—æ®µ
            Map<String, Object> metadataMap = metadata.toMap();
            metadataMap.put("question_id", index++);
            metadataMap.put("question", question);

            Document document = new Document(content, metadataMap);
            documents.add(document);
        }

        csvParser.close();
        vectorStore.add(documents);

        return "æˆåŠŸå¯¼å…¥ " + documents.size() + " æ¡èœè°±é—®ç­”æ•°æ®ï¼ˆå¸¦å®Œæ•´å…ƒæ•°æ®ï¼‰ã€‚";

    } catch (IOException e) {
        log.error("å¯¼å…¥æ•°æ®å¤±è´¥", e);
        return "å¯¼å…¥æ•°æ®æ—¶å‘ç”Ÿé”™è¯¯ï¼š" + e.getMessage();
    }
}
```

#### éªŒæ”¶æ ‡å‡†

- [x] æ‰€æœ‰å¯¼å…¥çš„æ–‡æ¡£éƒ½åŒ…å«å®Œæ•´å…ƒæ•°æ®ï¼ˆè‡³å°‘ 7 ä¸ªå­—æ®µï¼‰
- [x] æ”¯æŒæŒ‰ `source` è¿‡æ»¤æ£€ç´¢
- [x] å¯é€šè¿‡ `doc_id` å”¯ä¸€æ ‡è¯†æ–‡æ¡£
- [x] å…ƒæ•°æ®åŒ…å«æ—¶é—´æˆ³å’Œå†…å®¹å“ˆå¸Œ

---

### ä»»åŠ¡ 1.2: å®ç°æ–‡æ¡£åˆ†å—ï¼ˆDocument Chunkingï¼‰

**é¢„è®¡å·¥ä½œé‡**: 1 å¤©

#### ç›®æ ‡

ä½¿ç”¨ Spring AI çš„ `TokenTextSplitter` å®ç°æ™ºèƒ½æ–‡æ¡£åˆ†å—ã€‚

#### å®æ–½æ­¥éª¤

1. **é…ç½® TokenTextSplitter Bean**

åœ¨ `com.xurx.springai.configuration.RagConfiguration.java` ä¸­æ·»åŠ :

```java
package com.xurx.springai.configuration;

import org.springframework.ai.transformer.splitter.TokenTextSplitter;
import org.springframework.context.annotation.Bean;
import org.springframework.context.annotation.Configuration;

@Configuration
public class RagConfiguration {

    /**
     * TokenTextSplitter - åŸºäº Token æ•°é‡çš„æ–‡æ¡£åˆ†å—å™¨
     * ä½¿ç”¨ CL100K_BASE ç¼–ç ï¼ˆå…¼å®¹ OpenAI æ¨¡å‹ï¼‰
     */
    @Bean
    public TokenTextSplitter tokenTextSplitter() {
        return new TokenTextSplitter(
            512,    // defaultChunkSize: æ¯å— 512 tokens
            100,    // minChunkSizeChars: æœ€å° 100 å­—ç¬¦
            20,     // minChunkLengthToEmbed: æœ€å°åµŒå…¥é•¿åº¦
            100,    // maxNumChunks: æœ€å¤š 100 å—
            true    // keepSeparator: ä¿ç•™åˆ†éš”ç¬¦
        );
    }
}
```

2. **åˆ›å»ºæ–‡æ¡£åˆ†å—æœåŠ¡**

åˆ›å»º `com.xurx.springai.service.DocumentChunkingService.java`:

```java
package com.xurx.springai.service;

import lombok.RequiredArgsConstructor;
import lombok.extern.slf4j.Slf4j;
import org.springframework.ai.document.Document;
import org.springframework.ai.transformer.splitter.TokenTextSplitter;
import org.springframework.stereotype.Service;

import java.util.List;
import java.util.Map;

@Service
@RequiredArgsConstructor
@Slf4j
public class DocumentChunkingService {

    private final TokenTextSplitter tokenTextSplitter;

    /**
     * å¯¹æ–‡æ¡£è¿›è¡Œæ™ºèƒ½åˆ†å—
     */
    public List<Document> chunkDocument(Document document) {
        // æ£€æŸ¥æ–‡æ¡£é•¿åº¦ï¼ŒçŸ­æ–‡æ¡£ä¸åˆ†å—
        String content = document.getContent();
        if (content.length() < 500) {
            log.debug("æ–‡æ¡£é•¿åº¦å°äº 500 å­—ç¬¦ï¼Œè·³è¿‡åˆ†å—");
            return List.of(document);
        }

        // æ‰§è¡Œåˆ†å—
        List<Document> chunks = tokenTextSplitter.apply(List.of(document));
        log.info("æ–‡æ¡£å·²åˆ†å—ï¼šåŸå§‹é•¿åº¦ {} å­—ç¬¦ï¼Œåˆ†ä¸º {} å—", content.length(), chunks.size());

        // ä¸ºæ¯ä¸ªåˆ†å—æ·»åŠ é¢å¤–å…ƒæ•°æ®
        String parentDocId = (String) document.getMetadata().get("doc_id");
        for (int i = 0; i < chunks.size(); i++) {
            Map<String, Object> chunkMetadata = chunks.get(i).getMetadata();
            chunkMetadata.put("parent_doc_id", parentDocId);
            chunkMetadata.put("chunk_index", i);
            chunkMetadata.put("total_chunks", chunks.size());
            chunkMetadata.put("is_chunked", true);
        }

        return chunks;
    }

    /**
     * æ‰¹é‡åˆ†å—
     */
    public List<Document> chunkDocuments(List<Document> documents) {
        return documents.stream()
            .flatMap(doc -> chunkDocument(doc).stream())
            .toList();
    }
}
```

3. **é›†æˆåˆ°æ•°æ®å¯¼å…¥æµç¨‹**

ä¿®æ”¹ `RagController.java`:

```java
@RequiredArgsConstructor
public class RagController {

    private final VectorStore vectorStore;
    private final DocumentChunkingService chunkingService;  // æ³¨å…¥åˆ†å—æœåŠ¡

    @PostMapping("/importData")
    public String importData(@RequestParam String data,
                              @RequestParam(required = false, defaultValue = "manual_import") String source,
                              @RequestParam(required = false) String category,
                              @RequestParam(required = false, defaultValue = "text") String docType,
                              @RequestParam(required = false, defaultValue = "true") boolean enableChunking) {

        // ... æ„å»ºå…ƒæ•°æ®å’Œæ–‡æ¡£ï¼ˆåŒä¸Šï¼‰

        Document document = new Document(cleanedData, metadata.toMap());

        // åˆ†å—å¤„ç†
        List<Document> documentsToAdd = enableChunking
            ? chunkingService.chunkDocument(document)
            : List.of(document);

        vectorStore.add(documentsToAdd);

        return String.format("å¯¼å…¥æˆåŠŸï¼š%d ä¸ªæ–‡æ¡£å—ï¼ˆåŸå§‹æ–‡æ¡£ID: %sï¼‰",
            documentsToAdd.size(), metadata.getDocId());
    }
}
```

4. **æ·»åŠ åˆ†å—é…ç½®**

åœ¨ `application.yaml` ä¸­æ·»åŠ :

```yaml
rag:
  chunking:
    enabled: true
    strategy: token  # token | paragraph
    chunk-size: 512
    chunk-overlap: 50
    min-chunk-size: 100
```

#### éªŒæ”¶æ ‡å‡†

- [x] é•¿æ–‡æ¡£ï¼ˆ>500 å­—ç¬¦ï¼‰è¢«è‡ªåŠ¨åˆ†å—
- [x] æ¯ä¸ªåˆ†å—ä¿ç•™åŸå§‹æ–‡æ¡£çš„å…ƒæ•°æ®
- [x] åˆ†å—è¾¹ç•Œåœ¨è¯­ä¹‰å®Œæ•´çš„ä½ç½®ï¼ˆè‡ªåŠ¨å¤„ç†ï¼‰
- [x] å¯é€šè¿‡ `parent_doc_id` è¿½æº¯åŸå§‹æ–‡æ¡£
- [x] çŸ­æ–‡æ¡£ä¸ä¼šè¢«åˆ†å—

---

### ä»»åŠ¡ 1.3: åŠ¨æ€é…ç½®æ£€ç´¢å‚æ•°

**é¢„è®¡å·¥ä½œé‡**: 0.5 å¤©

#### ç›®æ ‡

å°†ç¡¬ç¼–ç çš„æ£€ç´¢å‚æ•°æ”¹ä¸ºé…ç½®æ–‡ä»¶ç®¡ç†ã€‚

#### å®æ–½æ­¥éª¤

1. **åˆ›å»º RAG é…ç½®å±æ€§ç±»**

åˆ›å»º `com.xurx.springai.configuration.RagProperties.java`:

```java
package com.xurx.springai.configuration;

import lombok.Data;
import org.springframework.boot.context.properties.ConfigurationProperties;
import org.springframework.stereotype.Component;

@Data
@Component
@ConfigurationProperties(prefix = "rag.retrieval")
public class RagProperties {

    /**
     * è¿”å›çš„æ–‡æ¡£æ•°é‡
     */
    private int topK = 5;

    /**
     * ç›¸ä¼¼åº¦é˜ˆå€¼ï¼ˆ0.0-1.0ï¼‰
     */
    private double similarityThreshold = 0.7;

    /**
     * æ˜¯å¦å¯ç”¨å…ƒæ•°æ®è¿‡æ»¤
     */
    private boolean enableMetadataFilter = false;

    /**
     * é»˜è®¤è¿‡æ»¤è¡¨è¾¾å¼
     */
    private String defaultFilterExpression = null;
}
```

2. **ä¿®æ”¹ ChatClientConfiguration**

ä¿®æ”¹ `com.xurx.springai.configuration.ChatClientConfiguration.java`:

```java
@Configuration
@RequiredArgsConstructor
public class ChatClientConfiguration {

    private final RagProperties ragProperties;  // æ³¨å…¥é…ç½®

    /**
     * å‘é‡æ£€ç´¢å™¨ - ä½¿ç”¨åŠ¨æ€é…ç½®
     */
    @Bean
    public VectorStoreDocumentRetriever vectorStoreDocumentRetriever(VectorStore vectorStore) {
        return VectorStoreDocumentRetriever.builder()
            .topK(ragProperties.getTopK())                              // ä»é…ç½®è¯»å–
            .vectorStore(vectorStore)
            .similarityThreshold(ragProperties.getSimilarityThreshold()) // ä»é…ç½®è¯»å–
            .build();
    }
}
```

3. **åœ¨ application.yaml ä¸­æ·»åŠ é…ç½®**

```yaml
rag:
  retrieval:
    top-k: 5
    similarity-threshold: 0.7  # ä» 0.8 é™ä½åˆ° 0.7ï¼Œæé«˜å¬å›ç‡
    enable-metadata-filter: false
    default-filter-expression: null
```

4. **æ·»åŠ ç¯å¢ƒå·®å¼‚åŒ–é…ç½®**

åœ¨ `application-dev.yaml` ä¸­:

```yaml
rag:
  retrieval:
    top-k: 5
    similarity-threshold: 0.65  # å¼€å‘ç¯å¢ƒæ›´å®½æ¾
```

åœ¨ `application-prod.yaml` ä¸­:

```yaml
rag:
  retrieval:
    top-k: 3
    similarity-threshold: 0.75  # ç”Ÿäº§ç¯å¢ƒæ›´ä¸¥æ ¼
```

#### éªŒæ”¶æ ‡å‡†

- [x] æ£€ç´¢å‚æ•°å¯é€šè¿‡é…ç½®æ–‡ä»¶ä¿®æ”¹
- [x] æ”¯æŒä¸åŒç¯å¢ƒä½¿ç”¨ä¸åŒé…ç½®
- [x] ä¿®æ”¹é…ç½®åé‡å¯å³ç”Ÿæ•ˆï¼Œæ— éœ€é‡æ–°ç¼–è¯‘

---

### ä»»åŠ¡ 1.4: æ”¹è¿›æ•°æ®å¯¼å…¥æµç¨‹

**é¢„è®¡å·¥ä½œé‡**: 1 å¤©

#### ç›®æ ‡

å¢å¼ºæ•°æ®å¯¼å…¥çš„å¥å£®æ€§ã€æ”¯æŒå»é‡ã€æ‰¹é‡å¯¼å…¥ã€‚

#### å®æ–½æ­¥éª¤

1. **åˆ›å»ºæ•°æ®æ¸…æ´—å·¥å…·ç±»**

åˆ›å»º `com.xurx.springai.util.TextCleaningUtils.java`:

```java
package com.xurx.springai.util;

public class TextCleaningUtils {

    /**
     * æ¸…æ´—æ–‡æœ¬å†…å®¹
     */
    public static String cleanText(String text) {
        if (text == null) return "";

        return text
            .trim()
            .replaceAll("\\s+", " ")                          // åˆå¹¶å¤šä½™ç©ºæ ¼
            .replaceAll("[\\x00-\\x08\\x0B\\x0C\\x0E-\\x1F]", "")  // ç§»é™¤æ§åˆ¶å­—ç¬¦
            .replaceAll("^\\uFEFF", "");                      // ç§»é™¤ BOM
    }

    /**
     * æ£€æŸ¥æ–‡æœ¬æ˜¯å¦æœ‰æ•ˆ
     */
    public static boolean isValidText(String text) {
        return text != null && !text.trim().isEmpty() && text.length() >= 10;
    }
}
```

2. **åˆ›å»ºå¢å¼ºçš„æ•°æ®å¯¼å…¥æœåŠ¡**

åˆ›å»º `com.xurx.springai.service.DocumentImportService.java`:

```java
package com.xurx.springai.service;

import com.xurx.springai.model.DocumentMetadata;
import com.xurx.springai.model.ImportResult;
import com.xurx.springai.util.TextCleaningUtils;
import lombok.RequiredArgsConstructor;
import lombok.extern.slf4j.Slf4j;
import org.apache.commons.codec.digest.DigestUtils;
import org.springframework.ai.document.Document;
import org.springframework.ai.vectorstore.SearchRequest;
import org.springframework.ai.vectorstore.VectorStore;
import org.springframework.stereotype.Service;

import java.time.Instant;
import java.util.ArrayList;
import java.util.List;
import java.util.UUID;

@Service
@RequiredArgsConstructor
@Slf4j
public class DocumentImportService {

    private final VectorStore vectorStore;
    private final DocumentChunkingService chunkingService;

    private static final int BATCH_SIZE = 100;

    /**
     * æ‰¹é‡å¯¼å…¥æ–‡æ¡£ï¼ˆå¸¦å»é‡ã€æ¸…æ´—ã€è¿›åº¦åé¦ˆï¼‰
     */
    public ImportResult importDocuments(List<String> textList, String source, String category) {
        ImportResult result = new ImportResult();
        List<Document> documentsToAdd = new ArrayList<>();

        for (int i = 0; i < textList.size(); i++) {
            String text = textList.get(i);

            // 1. æ¸…æ´—
            String cleanedText = TextCleaningUtils.cleanText(text);
            if (!TextCleaningUtils.isValidText(cleanedText)) {
                result.incrementSkipped();
                log.debug("æ–‡æ¡£ {} æ— æ•ˆï¼Œå·²è·³è¿‡", i);
                continue;
            }

            // 2. å»é‡æ£€æŸ¥
            String contentHash = DigestUtils.md5Hex(cleanedText);
            if (isDuplicate(contentHash)) {
                result.incrementSkipped();
                log.debug("æ–‡æ¡£ {} é‡å¤ï¼Œå·²è·³è¿‡ï¼ˆhash: {}ï¼‰", i, contentHash);
                continue;
            }

            // 3. æ„å»ºæ–‡æ¡£
            DocumentMetadata metadata = DocumentMetadata.builder()
                .docId(UUID.randomUUID().toString())
                .source(source)
                .category(category)
                .timestamp(Instant.now().toString())
                .contentHash(contentHash)
                .charCount(cleanedText.length())
                .build();

            Document document = new Document(cleanedText, metadata.toMap());

            // 4. åˆ†å—
            List<Document> chunks = chunkingService.chunkDocument(document);
            documentsToAdd.addAll(chunks);

            // 5. æ‰¹é‡æ·»åŠ 
            if (documentsToAdd.size() >= BATCH_SIZE) {
                try {
                    vectorStore.add(documentsToAdd);
                    result.addSuccessful(documentsToAdd.size());
                    log.info("å·²å¯¼å…¥ {} ä¸ªæ–‡æ¡£å—", documentsToAdd.size());
                    documentsToAdd.clear();
                } catch (Exception e) {
                    result.addFailed(documentsToAdd.size());
                    log.error("æ‰¹é‡å¯¼å…¥å¤±è´¥", e);
                    documentsToAdd.clear();
                }
            }
        }

        // 6. å¯¼å…¥å‰©ä½™æ–‡æ¡£
        if (!documentsToAdd.isEmpty()) {
            try {
                vectorStore.add(documentsToAdd);
                result.addSuccessful(documentsToAdd.size());
            } catch (Exception e) {
                result.addFailed(documentsToAdd.size());
                log.error("æœ€åä¸€æ‰¹å¯¼å…¥å¤±è´¥", e);
            }
        }

        return result;
    }

    /**
     * æ£€æŸ¥æ–‡æ¡£æ˜¯å¦é‡å¤
     */
    private boolean isDuplicate(String contentHash) {
        try {
            SearchRequest request = SearchRequest.builder()
                .topK(1)
                .filterExpression("content_hash == '" + contentHash + "'")
                .build();

            List<Document> existing = vectorStore.similaritySearch(request);
            return !existing.isEmpty();
        } catch (Exception e) {
            log.warn("å»é‡æ£€æŸ¥å¤±è´¥ï¼Œè·³è¿‡æ£€æŸ¥", e);
            return false;
        }
    }
}
```

3. **åˆ›å»ºå¯¼å…¥ç»“æœ DTO**

åˆ›å»º `com.xurx.springai.model.ImportResult.java`:

```java
package com.xurx.springai.model;

import lombok.Data;

@Data
public class ImportResult {
    private int successful = 0;
    private int failed = 0;
    private int skipped = 0;

    public void addSuccessful(int count) {
        this.successful += count;
    }

    public void addFailed(int count) {
        this.failed += count;
    }

    public void incrementSkipped() {
        this.skipped++;
    }

    public int getTotal() {
        return successful + failed + skipped;
    }

    @Override
    public String toString() {
        return String.format("å¯¼å…¥å®Œæˆ - æ€»è®¡: %d, æˆåŠŸ: %d, å¤±è´¥: %d, è·³è¿‡: %d",
            getTotal(), successful, failed, skipped);
    }
}
```

4. **æ”¹é€  Controller ä½¿ç”¨æ–°æœåŠ¡**

ä¿®æ”¹ `RagController.java`:

```java
@PostMapping("/importBatch")
public ImportResult importBatch(@RequestBody ImportBatchRequest request) {
    return documentImportService.importDocuments(
        request.getTexts(),
        request.getSource(),
        request.getCategory()
    );
}
```

#### éªŒæ”¶æ ‡å‡†

- [x] é‡å¤æ–‡æ¡£ä¸ä¼šè¢«é‡å¤å¯¼å…¥
- [x] å¯¼å…¥é€Ÿåº¦æå‡ 3-5 å€ï¼ˆæ‰¹é‡å¯¼å…¥ï¼‰
- [x] æä¾›è¯¦ç»†çš„å¯¼å…¥æŠ¥å‘Šï¼ˆæˆåŠŸ/å¤±è´¥/è·³è¿‡ï¼‰
- [x] è‡ªåŠ¨æ¸…æ´—æ–‡æœ¬å†…å®¹

---

### ä»»åŠ¡ 1.5: æ·»åŠ å¼•ç”¨æ¥æºï¼ˆCitationï¼‰

**é¢„è®¡å·¥ä½œé‡**: 1 å¤©

#### ç›®æ ‡

åœ¨ AI å›ç­”ä¸­æ˜¾ç¤ºå¼•ç”¨çš„æ–‡æ¡£æ¥æºï¼Œæé«˜å¯ä¿¡åº¦ã€‚

#### å®æ–½æ­¥éª¤

1. **åˆ›å»ºå“åº” DTO**

åˆ›å»º `com.xurx.springai.model.ChatResponseDTO.java`:

```java
package com.xurx.springai.model;

import lombok.Builder;
import lombok.Data;
import java.util.List;
import java.util.Map;

@Data
@Builder
public class ChatResponseDTO {
    private String content;              // AI å›ç­”å†…å®¹
    private List<DocumentSource> sources; // å¼•ç”¨æ¥æº
    private Map<String, Object> metadata; // é¢å¤–å…ƒæ•°æ®
}

@Data
@Builder
class DocumentSource {
    private String docId;           // æ–‡æ¡£ID
    private String source;          // æ¥æºåç§°
    private String snippet;         // æ–‡æ¡£ç‰‡æ®µï¼ˆå‰100å­—ï¼‰
    private Double similarityScore; // ç›¸ä¼¼åº¦åˆ†æ•°
    private String category;        // åˆ†ç±»
}
```

2. **åˆ›å»ºå¼•ç”¨æ¥æºæå–æœåŠ¡**

åˆ›å»º `com.xurx.springai.service.CitationService.java`:

```java
package com.xurx.springai.service;

import com.xurx.springai.model.DocumentSource;
import lombok.extern.slf4j.Slf4j;
import org.springframework.ai.chat.client.ChatClient;
import org.springframework.ai.chat.model.ChatResponse;
import org.springframework.ai.document.Document;
import org.springframework.stereotype.Service;

import java.util.List;
import java.util.stream.Collectors;

@Service
@Slf4j
public class CitationService {

    /**
     * ä» ChatResponse ä¸­æå–æ£€ç´¢åˆ°çš„æ–‡æ¡£
     * æ³¨æ„ï¼šè¿™éœ€è¦è®¿é—® advisor context
     */
    public List<Document> extractRetrievedDocuments(ChatResponse response) {
        // Spring AI 1.1.0 ä¼šåœ¨ metadata ä¸­å­˜å‚¨æ£€ç´¢çš„æ–‡æ¡£
        // å…·ä½“å®ç°å¯èƒ½éœ€è¦æ ¹æ®å®é™…è¿”å›ç»“æ„è°ƒæ•´
        Object docs = response.getMetadata().get("retrieved_documents");

        if (docs instanceof List<?>) {
            return ((List<?>) docs).stream()
                .filter(obj -> obj instanceof Document)
                .map(obj -> (Document) obj)
                .collect(Collectors.toList());
        }

        return List.of();
    }

    /**
     * æ„å»ºæ–‡æ¡£æ¥æºåˆ—è¡¨
     */
    public List<DocumentSource> buildSources(List<Document> documents) {
        return documents.stream()
            .map(doc -> DocumentSource.builder()
                .docId((String) doc.getMetadata().get("doc_id"))
                .source((String) doc.getMetadata().get("source"))
                .snippet(truncate(doc.getContent(), 100))
                .similarityScore((Double) doc.getMetadata().get("similarity_score"))
                .category((String) doc.getMetadata().get("category"))
                .build())
            .collect(Collectors.toList());
    }

    /**
     * æ ¼å¼åŒ–ä¸º Markdown å¼•ç”¨
     */
    public String formatCitations(List<DocumentSource> sources) {
        if (sources.isEmpty()) {
            return "";
        }

        StringBuilder sb = new StringBuilder("\n\n---\n**å‚è€ƒæ¥æºï¼š**\n");
        for (int i = 0; i < sources.size(); i++) {
            DocumentSource source = sources.get(i);
            sb.append(String.format("[%d] %s (æ¥æº: %s, ç›¸ä¼¼åº¦: %.2f)\n",
                i + 1,
                source.getSnippet(),
                source.getSource(),
                source.getSimilarityScore() != null ? source.getSimilarityScore() : 0.0
            ));
        }

        return sb.toString();
    }

    private String truncate(String text, int maxLength) {
        if (text == null) return "";
        return text.length() <= maxLength ? text : text.substring(0, maxLength) + "...";
    }
}
```

3. **æ”¹é€  ChatController**

ä¿®æ”¹ `com.xurx.springai.controller.ChatController.java`:

```java
@RestController
@RequestMapping("/chat")
@RequiredArgsConstructor
public class ChatController {

    private final Map<String, ChatClient> chatClientMap;
    private final CitationService citationService;

    /**
     * è¿”å› JSON æ ¼å¼ï¼ˆå¸¦å¼•ç”¨æ¥æºï¼‰
     */
    @PostMapping(produces = "application/json;charset=utf-8")
    public ChatResponseDTO chatPostJson(@RequestBody ChatRequest chatRequest) {
        String model = chatRequest.getModel();
        String message = chatRequest.getMessage();

        ChatClient chatClient = chatClientMap.get(model);
        if (chatClient == null) {
            throw new IllegalArgumentException("æ¨¡å‹æœªæ‰¾åˆ°: " + model);
        }

        // è·å–å®Œæ•´å“åº”
        ChatResponse response = chatClient.prompt()
            .system(p -> p.param("name", "xrx").param("identity", "postgraduate"))
            .user(message)
            .call()
            .chatResponse();

        String content = response.getResult().getOutput().getContent();

        // æå–æ£€ç´¢çš„æ–‡æ¡£
        List<Document> retrievedDocs = citationService.extractRetrievedDocuments(response);
        List<DocumentSource> sources = citationService.buildSources(retrievedDocs);

        // æ„å»ºå“åº”
        return ChatResponseDTO.builder()
            .content(content)
            .sources(sources)
            .metadata(Map.of(
                "model", model,
                "retrieval_count", retrievedDocs.size()
            ))
            .build();
    }

    /**
     * è¿”å›çº¯æ–‡æœ¬æ ¼å¼ï¼ˆå¸¦å¼•ç”¨æ¥æºï¼‰
     */
    @PostMapping(produces = "text/plain;charset=utf-8")
    public String chatPostText(@RequestBody ChatRequest chatRequest) {
        ChatResponseDTO dto = chatPostJson(chatRequest);

        String citations = citationService.formatCitations(dto.getSources());
        return dto.getContent() + citations;
    }
}
```

4. **å‰ç«¯é€‚é…ï¼ˆå¯é€‰ï¼‰**

ä¿®æ”¹ `frontend/src/api/request.js`ï¼Œè§£æ JSON å“åº”å¹¶æ˜¾ç¤ºæ¥æºã€‚

#### éªŒæ”¶æ ‡å‡†

- [x] AI å›ç­”åŒ…å«å¼•ç”¨æ¥æºåˆ—è¡¨
- [x] æ¯ä¸ªæ¥æºæ˜¾ç¤ºï¼šæ–‡æ¡£ç‰‡æ®µã€æ¥æºåç§°ã€ç›¸ä¼¼åº¦åˆ†æ•°
- [x] æ”¯æŒ JSON å’Œçº¯æ–‡æœ¬ä¸¤ç§æ ¼å¼
- [x] å‰ç«¯å¯å±•ç¤ºå¯æŠ˜å çš„æ¥æºåˆ—è¡¨

---

## Phase 2: Level 2 è¿›é˜¶ä¼˜åŒ–

**ç›®æ ‡**: RAG èƒ½åŠ›æå‡åˆ° 85 åˆ†ï¼Œæ£€ç´¢å‡†ç¡®ç‡æå‡ 30%
**é¢„è®¡æ—¶é—´**: 5-6 å¤©

---

### ä»»åŠ¡ 2.1: å®ç°æŸ¥è¯¢é‡å†™ï¼ˆQuery Rewritingï¼‰

**é¢„è®¡å·¥ä½œé‡**: 1-2 å¤©

#### ç›®æ ‡

ä½¿ç”¨ Spring AI çš„ `RewriteQueryTransformer` ä¼˜åŒ–ç”¨æˆ·æŸ¥è¯¢ã€‚

#### å®æ–½æ­¥éª¤

1. **é…ç½® RewriteQueryTransformer Bean**

åœ¨ `RagConfiguration.java` ä¸­æ·»åŠ :

```java
/**
 * æŸ¥è¯¢é‡å†™è½¬æ¢å™¨
 */
@Bean
public RewriteQueryTransformer rewriteQueryTransformer(ChatModel chatModel) {
    return RewriteQueryTransformer.builder()
        .chatModel(chatModel)
        .build();
}
```

2. **è‡ªå®šä¹‰æŸ¥è¯¢é‡å†™æç¤ºè¯ï¼ˆå¯é€‰ï¼‰**

```java
@Bean
public RewriteQueryTransformer rewriteQueryTransformer(
        @Qualifier("deepseekChatModel") ChatModel chatModel) {

    String customPrompt = """
        ä½ æ˜¯ä¸€ä¸ªæŸ¥è¯¢ä¼˜åŒ–ä¸“å®¶ã€‚ç”¨æˆ·çš„æŸ¥è¯¢å¯èƒ½å«ç³Šä¸æ¸…æˆ–è¡¨è¾¾ä¸å®Œæ•´ã€‚
        è¯·å°†ç”¨æˆ·æŸ¥è¯¢æ”¹å†™ä¸ºæ›´æ¸…æ™°ã€æ›´å…·ä½“çš„æœç´¢æŸ¥è¯¢ã€‚

        è§„åˆ™ï¼š
        1. è¡¥å……ç¼ºå¤±çš„å…³é”®ä¿¡æ¯
        2. å±•å¼€ç¼©å†™å’Œä»£è¯
        3. ä¿æŒåŸæ„ï¼Œä¸æ”¹å˜æŸ¥è¯¢æ„å›¾
        4. ç”¨ä¸­æ–‡å›ç­”

        ç¤ºä¾‹ï¼š
        è¾“å…¥ï¼š"è¿™ä¸ªæ€ä¹ˆåš"
        è¾“å‡ºï¼š"è¿™é“èœçš„å…·ä½“åšæ³•æ­¥éª¤æ˜¯ä»€ä¹ˆ"

        ç”¨æˆ·æŸ¥è¯¢ï¼š{query}
        ä¼˜åŒ–åçš„æŸ¥è¯¢ï¼š
        """;

    return RewriteQueryTransformer.builder()
        .chatModel(chatModel)
        .systemPrompt(customPrompt)
        .build();
}
```

3. **é›†æˆåˆ° RetrievalAugmentationAdvisor**

ä¿®æ”¹ `ChatClientConfiguration.java`:

```java
@Bean
public RetrievalAugmentationAdvisor retrievalAugmentationAdvisor(
        VectorStoreDocumentRetriever retriever,
        RewriteQueryTransformer queryTransformer) {

    return RetrievalAugmentationAdvisor.builder()
        .documentRetriever(retriever)
        .queryTransformers(queryTransformer)  // æ·»åŠ æŸ¥è¯¢è½¬æ¢å™¨
        .queryAugmenter(ContextualQueryAugmenter.builder()
            .allowEmptyContext(true)
            .build())
        .build();
}
```

4. **æ·»åŠ é…ç½®å¼€å…³**

åœ¨ `application.yaml` ä¸­:

```yaml
rag:
  query-optimization:
    rewrite-enabled: true
    rewrite-model: deepseek  # ä½¿ç”¨ä¾¿å®œçš„æ¨¡å‹
```

#### éªŒæ”¶æ ‡å‡†

- [x] å«ç³Šçš„æŸ¥è¯¢è¢«æ”¹å†™ä¸ºæ›´æ¸…æ™°çš„æŸ¥è¯¢
- [x] æ£€ç´¢å‡†ç¡®ç‡æå‡ 10-15%
- [x] å¯é€šè¿‡é…ç½®å¼€å…³å¯ç”¨/ç¦ç”¨
- [x] æŸ¥è¯¢é‡å†™è€—æ—¶ < 500ms

---

### ä»»åŠ¡ 2.2: å®ç°æŸ¥è¯¢æ‰©å±•ï¼ˆQuery Expansionï¼‰

**é¢„è®¡å·¥ä½œé‡**: 1 å¤©

#### ç›®æ ‡

ä½¿ç”¨ Spring AI çš„ `MultiQueryExpander` ç”Ÿæˆå¤šä¸ªæŸ¥è¯¢å˜ä½“ã€‚

#### å®æ–½æ­¥éª¤

1. **é…ç½® MultiQueryExpander Bean**

```java
@Bean
public MultiQueryExpander multiQueryExpander(ChatModel chatModel) {
    return MultiQueryExpander.builder()
        .chatModel(chatModel)
        .build();
}
```

2. **è‡ªå®šä¹‰æ‰©å±•æç¤ºè¯**

```java
@Bean
public MultiQueryExpander multiQueryExpander(
        @Qualifier("deepseekChatModel") ChatModel chatModel) {

    String customPrompt = """
        ç”Ÿæˆ 2 ä¸ªä¸åŸæŸ¥è¯¢è¯­ä¹‰ç›¸è¿‘ä½†è¡¨è¾¾ä¸åŒçš„æŸ¥è¯¢å˜ä½“ã€‚
        è¦æ±‚ï¼š
        1. ä¿æŒåŸå§‹æŸ¥è¯¢çš„æ ¸å¿ƒæ„å›¾
        2. ä½¿ç”¨ä¸åŒçš„è¡¨è¾¾æ–¹å¼å’Œè¯æ±‡
        3. ç”¨æ¢è¡Œç¬¦åˆ†éš”ï¼Œä¸è¦ç¼–å·

        åŸå§‹æŸ¥è¯¢ï¼š{query}
        æŸ¥è¯¢å˜ä½“ï¼š
        """;

    return MultiQueryExpander.builder()
        .chatModel(chatModel)
        .systemPrompt(customPrompt)
        .build();
}
```

3. **é›†æˆåˆ° Advisor**

```java
@Bean
public RetrievalAugmentationAdvisor retrievalAugmentationAdvisor(
        VectorStoreDocumentRetriever retriever,
        RewriteQueryTransformer queryTransformer,
        MultiQueryExpander queryExpander) {

    return RetrievalAugmentationAdvisor.builder()
        .documentRetriever(retriever)
        .queryTransformers(queryTransformer)
        .queryExpanders(queryExpander)  // æ·»åŠ æŸ¥è¯¢æ‰©å±•å™¨
        .queryAugmenter(ContextualQueryAugmenter.builder()
            .allowEmptyContext(true)
            .build())
        .build();
}
```

4. **é…ç½®**

```yaml
rag:
  query-optimization:
    expand-enabled: true
    expand-count: 2  # ç”Ÿæˆ 2 ä¸ªå˜ä½“
```

#### éªŒæ”¶æ ‡å‡†

- [x] æ¯ä¸ªç”¨æˆ·æŸ¥è¯¢ç”Ÿæˆ 2 ä¸ªè¯­ä¹‰ç›¸å…³çš„å˜ä½“
- [x] æ£€ç´¢å¬å›ç‡æå‡ 15-20%
- [x] è‡ªåŠ¨å»é‡åˆå¹¶å¤šä¸ªæŸ¥è¯¢çš„ç»“æœ

---

### ä»»åŠ¡ 2.3: å®ç°æŸ¥è¯¢å‹ç¼©ï¼ˆQuery Compressionï¼‰

**é¢„è®¡å·¥ä½œé‡**: 1 å¤©

#### ç›®æ ‡

ä½¿ç”¨ `CompressionQueryTransformer` å‹ç¼©å†—é•¿æŸ¥è¯¢ã€‚

#### å®æ–½æ­¥éª¤

1. **é…ç½® CompressionQueryTransformer**

```java
@Bean
public CompressionQueryTransformer compressionQueryTransformer(ChatModel chatModel) {
    return CompressionQueryTransformer.builder()
        .chatModel(chatModel)
        .build();
}
```

2. **é›†æˆåˆ° Advisor Pipeline**

```java
@Bean
public RetrievalAugmentationAdvisor retrievalAugmentationAdvisor(
        VectorStoreDocumentRetriever retriever,
        CompressionQueryTransformer compressionTransformer,
        RewriteQueryTransformer rewriteTransformer) {

    return RetrievalAugmentationAdvisor.builder()
        .documentRetriever(retriever)
        .queryTransformers(
            compressionTransformer,  // å…ˆå‹ç¼©
            rewriteTransformer       // å†é‡å†™
        )
        .build();
}
```

3. **é…ç½®**

```yaml
rag:
  query-optimization:
    compression-enabled: true
```

#### éªŒæ”¶æ ‡å‡†

- [x] å†—é•¿çš„ç”¨æˆ·æŸ¥è¯¢è¢«å‹ç¼©ä¸ºæ ¸å¿ƒé—®é¢˜
- [x] æé«˜æ£€ç´¢æ•ˆç‡
- [x] å‹ç¼©åæŸ¥è¯¢é•¿åº¦å‡å°‘ 30-50%

---

### ä»»åŠ¡ 2.4: å®ç°é‡æ’åºï¼ˆRerankingï¼‰

**é¢„è®¡å·¥ä½œé‡**: 2 å¤©

#### ç›®æ ‡

å¯¹æ£€ç´¢ç»“æœè¿›è¡ŒäºŒæ¬¡æ’åºï¼Œæå‡ç›¸å…³æ€§ã€‚

#### å®æ–½æ­¥éª¤

1. **åˆ›å»ºé‡æ’åºæœåŠ¡**

åˆ›å»º `com.xurx.springai.service.RerankingService.java`:

```java
package com.xurx.springai.service;

import lombok.extern.slf4j.Slf4j;
import org.springframework.ai.document.Document;
import org.springframework.stereotype.Service;

import java.time.Instant;
import java.time.temporal.ChronoUnit;
import java.util.Arrays;
import java.util.Comparator;
import java.util.List;

@Service
@Slf4j
public class RerankingService {

    /**
     * åŸºäºç‰¹å¾çš„é‡æ’åº
     */
    public List<Document> rerankByFeatures(String query, List<Document> documents) {
        List<String> queryTerms = Arrays.asList(query.toLowerCase().split("\\s+"));

        return documents.stream()
            .peek(doc -> {
                double score = 0.0;
                String text = doc.getContent().toLowerCase();

                // ç‰¹å¾1: å…³é”®è¯è¦†ç›–ç‡ (40%)
                long matchedTerms = queryTerms.stream()
                    .filter(text::contains)
                    .count();
                score += (double) matchedTerms / queryTerms.size() * 0.4;

                // ç‰¹å¾2: æ–‡æ¡£æ–°é²œåº¦ (20%)
                if (doc.getMetadata().containsKey("timestamp")) {
                    try {
                        Instant timestamp = Instant.parse((String) doc.getMetadata().get("timestamp"));
                        long daysSince = ChronoUnit.DAYS.between(timestamp, Instant.now());
                        score += Math.max(0, 1 - daysSince / 365.0) * 0.2;
                    } catch (Exception e) {
                        // å¿½ç•¥è§£æé”™è¯¯
                    }
                }

                // ç‰¹å¾3: æ–‡æ¡£è´¨é‡ - å­—æ•° (20%)
                Integer charCount = (Integer) doc.getMetadata().getOrDefault("char_count", 0);
                score += Math.min(charCount / 1000.0, 1.0) * 0.2;

                // ç‰¹å¾4: åŸå§‹ç›¸ä¼¼åº¦åˆ†æ•° (20%)
                Double similarityScore = (Double) doc.getMetadata().getOrDefault("similarity_score", 0.5);
                score += similarityScore * 0.2;

                doc.getMetadata().put("rerank_score", score);
            })
            .sorted(Comparator.comparingDouble(doc ->
                -((double) doc.getMetadata().get("rerank_score"))))
            .toList();
    }
}
```

2. **åˆ›å»ºè‡ªå®šä¹‰ DocumentPostProcessor**

åˆ›å»º `com.xurx.springai.advisor.RerankingDocumentPostProcessor.java`:

```java
package com.xurx.springai.advisor;

import com.xurx.springai.service.RerankingService;
import lombok.RequiredArgsConstructor;
import org.springframework.ai.document.Document;
import org.springframework.ai.rag.postretrieval.DocumentPostProcessor;
import org.springframework.stereotype.Component;

import java.util.List;

@Component
@RequiredArgsConstructor
public class RerankingDocumentPostProcessor implements DocumentPostProcessor {

    private final RerankingService rerankingService;

    @Override
    public List<Document> process(List<Document> documents, String query) {
        return rerankingService.rerankByFeatures(query, documents);
    }
}
```

3. **é›†æˆåˆ° RetrievalAugmentationAdvisor**

```java
@Bean
public RetrievalAugmentationAdvisor retrievalAugmentationAdvisor(
        VectorStoreDocumentRetriever retriever,
        RerankingDocumentPostProcessor rerankingProcessor) {

    return RetrievalAugmentationAdvisor.builder()
        .documentRetriever(retriever)
        .documentPostProcessors(rerankingProcessor)  // æ·»åŠ åå¤„ç†å™¨
        .build();
}
```

4. **é…ç½®**

```yaml
rag:
  reranking:
    enabled: true
    strategy: feature-based  # feature-based | llm-based
```

#### éªŒæ”¶æ ‡å‡†

- [x] æ£€ç´¢ç»“æœæŒ‰ç›¸å…³æ€§é‡æ–°æ’åº
- [x] æ£€ç´¢å‡†ç¡®ç‡æå‡ 10-15%
- [x] é‡æ’åºè€—æ—¶ < 100ms

---

### ä»»åŠ¡ 2.5: æ–‡æ¡£ç®¡ç† API

**é¢„è®¡å·¥ä½œé‡**: 2 å¤©

#### ç›®æ ‡

æä¾›å®Œæ•´çš„æ–‡æ¡£ CRUD æ¥å£ã€‚

#### å®æ–½æ­¥éª¤

1. **åˆ›å»º DocumentManagementController**

åˆ›å»º `com.xurx.springai.controller.DocumentManagementController.java`:

```java
package com.xurx.springai.controller;

import lombok.RequiredArgsConstructor;
import org.springframework.ai.document.Document;
import org.springframework.ai.vectorstore.SearchRequest;
import org.springframework.ai.vectorstore.VectorStore;
import org.springframework.data.domain.Page;
import org.springframework.data.domain.PageImpl;
import org.springframework.data.domain.PageRequest;
import org.springframework.data.redis.core.RedisTemplate;
import org.springframework.web.bind.annotation.*;

import java.util.List;
import java.util.Set;

@RestController
@RequestMapping("/rag/documents")
@RequiredArgsConstructor
public class DocumentManagementController {

    private final VectorStore vectorStore;
    private final RedisTemplate<String, String> redisTemplate;

    private static final String DOCUMENT_IDS_KEY = "xurx-prefix:document_ids";

    /**
     * åˆ—å‡ºæ‰€æœ‰æ–‡æ¡£ï¼ˆåˆ†é¡µï¼‰
     */
    @GetMapping
    public Page<String> listDocuments(@RequestParam(defaultValue = "0") int page,
                                       @RequestParam(defaultValue = "20") int size) {
        Set<String> docIds = redisTemplate.opsForSet().members(DOCUMENT_IDS_KEY);
        if (docIds == null) {
            return Page.empty();
        }

        List<String> docIdList = docIds.stream()
            .skip((long) page * size)
            .limit(size)
            .toList();

        return new PageImpl<>(docIdList, PageRequest.of(page, size), docIds.size());
    }

    /**
     * æ ¹æ® ID è·å–æ–‡æ¡£
     */
    @GetMapping("/{docId}")
    public Document getDocument(@PathVariable String docId) {
        SearchRequest request = SearchRequest.builder()
            .topK(1)
            .filterExpression("doc_id == '" + docId + "'")
            .build();

        List<Document> docs = vectorStore.similaritySearch(request);
        if (docs.isEmpty()) {
            throw new ResourceNotFoundException("æ–‡æ¡£æœªæ‰¾åˆ°: " + docId);
        }

        return docs.get(0);
    }

    /**
     * æ›´æ–°æ–‡æ¡£
     */
    @PutMapping("/{docId}")
    public String updateDocument(@PathVariable String docId,
                                  @RequestBody DocumentUpdateRequest request) {
        // 1. åˆ é™¤æ—§æ–‡æ¡£
        vectorStore.delete(List.of(docId));

        // 2. æ·»åŠ æ–°æ–‡æ¡£ï¼ˆä¿ç•™ doc_idï¼‰
        Document newDoc = new Document(
            request.getText(),
            request.getMetadata()
        );
        newDoc.getMetadata().put("doc_id", docId);
        newDoc.getMetadata().put("updated_at", Instant.now().toString());

        vectorStore.add(List.of(newDoc));

        return "æ–‡æ¡£æ›´æ–°æˆåŠŸ: " + docId;
    }

    /**
     * åˆ é™¤æ–‡æ¡£
     */
    @DeleteMapping("/{docId}")
    public String deleteDocument(@PathVariable String docId) {
        vectorStore.delete(List.of(docId));
        redisTemplate.opsForSet().remove(DOCUMENT_IDS_KEY, docId);
        return "æ–‡æ¡£åˆ é™¤æˆåŠŸ: " + docId;
    }

    /**
     * æ‰¹é‡åˆ é™¤
     */
    @DeleteMapping("/batch")
    public String batchDelete(@RequestBody List<String> docIds) {
        vectorStore.delete(docIds);
        docIds.forEach(id -> redisTemplate.opsForSet().remove(DOCUMENT_IDS_KEY, id));
        return "æ‰¹é‡åˆ é™¤æˆåŠŸï¼š" + docIds.size() + " ä¸ªæ–‡æ¡£";
    }

    /**
     * é«˜çº§æœç´¢
     */
    @PostMapping("/search")
    public List<Document> searchDocuments(@RequestBody DocumentSearchRequest request) {
        SearchRequest.Builder builder = SearchRequest.builder()
            .query(request.getQuery())
            .topK(request.getTopK());

        // æ·»åŠ è¿‡æ»¤æ¡ä»¶
        if (request.getSource() != null) {
            builder.filterExpression("source == '" + request.getSource() + "'");
        }
        if (request.getCategory() != null) {
            builder.filterExpression("category == '" + request.getCategory() + "'");
        }

        return vectorStore.similaritySearch(builder.build());
    }
}
```

2. **åˆ›å»ºè¯·æ±‚ DTO**

```java
@Data
public class DocumentUpdateRequest {
    private String text;
    private Map<String, Object> metadata;
}

@Data
public class DocumentSearchRequest {
    private String query;
    private Integer topK = 10;
    private String source;
    private String category;
    private String docType;
}
```

3. **ç»´æŠ¤æ–‡æ¡£ç´¢å¼•**

ä¿®æ”¹ `DocumentImportService`ï¼Œå¯¼å…¥æ—¶ç»´æŠ¤æ–‡æ¡£ ID åˆ—è¡¨:

```java
// å¯¼å…¥æˆåŠŸåï¼Œæ·»åŠ åˆ° Redis Set
String docId = (String) document.getMetadata().get("doc_id");
redisTemplate.opsForSet().add(DOCUMENT_IDS_KEY, docId);
```

#### éªŒæ”¶æ ‡å‡†

- [x] æä¾›å®Œæ•´çš„æ–‡æ¡£ CRUD æ¥å£
- [x] æ”¯æŒåˆ†é¡µåˆ—è¡¨
- [x] æ”¯æŒæŒ‰å…ƒæ•°æ®è¿‡æ»¤å’Œæœç´¢
- [x] æ”¯æŒæ–‡æ¡£æ›´æ–°å’Œåˆ é™¤
- [x] æ”¯æŒæ‰¹é‡åˆ é™¤

---

## å®æ–½æ—¶é—´è¡¨

### Week 1: Level 1 åŸºç¡€ä¼˜åŒ–

| æ—¥æœŸ | ä»»åŠ¡ | é¢„è®¡å·¥ä½œé‡ | è´Ÿè´£äºº |
|------|------|-----------|--------|
| Day 1 ä¸Šåˆ | ä»»åŠ¡ 1.1: æ·»åŠ æ–‡æ¡£å…ƒæ•°æ® | 4 å°æ—¶ | - |
| Day 1 ä¸‹åˆ | ä»»åŠ¡ 1.3: åŠ¨æ€é…ç½®å‚æ•° | 4 å°æ—¶ | - |
| Day 2 å…¨å¤© | ä»»åŠ¡ 1.2: å®ç°æ–‡æ¡£åˆ†å— | 8 å°æ—¶ | - |
| Day 3 å…¨å¤© | ä»»åŠ¡ 1.4: æ”¹è¿›æ•°æ®å¯¼å…¥ | 8 å°æ—¶ | - |
| Day 4 å…¨å¤© | ä»»åŠ¡ 1.5: æ·»åŠ å¼•ç”¨æ¥æº | 8 å°æ—¶ | - |

**Week 1 é‡Œç¨‹ç¢‘**:
- âœ… RAG åŸºç¡€èƒ½åŠ›ä» 60 åˆ†æå‡åˆ° 75 åˆ†
- âœ… æ‰€æœ‰æ–‡æ¡£æœ‰å®Œæ•´å…ƒæ•°æ®å’Œåˆ†å—
- âœ… æ”¯æŒå¼•ç”¨æ¥æºè¿½æº¯

---

### Week 2-3: Level 2 è¿›é˜¶ä¼˜åŒ–

| æ—¥æœŸ | ä»»åŠ¡ | é¢„è®¡å·¥ä½œé‡ | è´Ÿè´£äºº |
|------|------|-----------|--------|
| Day 5-6 | ä»»åŠ¡ 2.1: æŸ¥è¯¢é‡å†™ | 12 å°æ—¶ | - |
| Day 7 | ä»»åŠ¡ 2.2: æŸ¥è¯¢æ‰©å±• | 8 å°æ—¶ | - |
| Day 8 | ä»»åŠ¡ 2.3: æŸ¥è¯¢å‹ç¼© | 8 å°æ—¶ | - |
| Day 9-10 | ä»»åŠ¡ 2.4: å®ç°é‡æ’åº | 12 å°æ—¶ | - |
| Day 11-12 | ä»»åŠ¡ 2.5: æ–‡æ¡£ç®¡ç† API | 16 å°æ—¶ | - |
| Day 13 | é›†æˆæµ‹è¯•å’Œæ€§èƒ½ä¼˜åŒ– | 8 å°æ—¶ | - |

**Week 2-3 é‡Œç¨‹ç¢‘**:
- âœ… RAG èƒ½åŠ›æå‡åˆ° 85 åˆ†
- âœ… æ£€ç´¢å‡†ç¡®ç‡æå‡ 30%
- âœ… å®Œæ•´çš„æ–‡æ¡£ç®¡ç†åŠŸèƒ½

---

## é…ç½®å˜æ›´

### 1. Maven ä¾èµ–

ç¡®ä¿ `pom.xml` åŒ…å«ä»¥ä¸‹ä¾èµ–ï¼š

```xml
<!-- Apache Commons Codecï¼ˆç”¨äº MD5ï¼‰ -->
<dependency>
    <groupId>commons-codec</groupId>
    <artifactId>commons-codec</artifactId>
</dependency>
```

### 2. application.yaml å®Œæ•´é…ç½®

```yaml
rag:
  # æ£€ç´¢é…ç½®
  retrieval:
    top-k: 5
    similarity-threshold: 0.7
    enable-metadata-filter: false

  # åˆ†å—é…ç½®
  chunking:
    enabled: true
    strategy: token  # token | paragraph
    chunk-size: 512
    chunk-overlap: 50
    min-chunk-size: 100

  # æŸ¥è¯¢ä¼˜åŒ–é…ç½®
  query-optimization:
    rewrite-enabled: true
    expand-enabled: true
    compression-enabled: true
    rewrite-model: deepseek  # ä½¿ç”¨ä¾¿å®œçš„æ¨¡å‹
    expand-count: 2

  # é‡æ’åºé…ç½®
  reranking:
    enabled: true
    strategy: feature-based  # feature-based | llm-based
```

### 3. Redis é…ç½®

ç»´æŠ¤æ–‡æ¡£ç´¢å¼• Key:

```
xurx-prefix:document_ids  (Set ç±»å‹ï¼Œå­˜å‚¨æ‰€æœ‰æ–‡æ¡£ ID)
```

---

## é¢„æœŸæ”¶ç›Š

### æŒ‡æ ‡å¯¹æ¯”

| æŒ‡æ ‡ | å½“å‰å®ç° | Level 1 å®Œæˆå | Level 2 å®Œæˆå |
|------|---------|---------------|---------------|
| **æ£€ç´¢å‡†ç¡®ç‡** | 65% | 75% (+15%) | 85% (+31%) |
| **æ£€ç´¢å¬å›ç‡** | 60% | 70% (+17%) | 82% (+37%) |
| **å“åº”ç›¸å…³æ€§** | 70% | 78% (+11%) | 88% (+26%) |
| **å¹³å‡å“åº”æ—¶é—´** | 1.2s | 1.3s | 1.6s |
| **æ”¯æŒæ–‡æ¡£ç±»å‹** | çº¯æ–‡æœ¬ | çº¯æ–‡æœ¬ + å…ƒæ•°æ® + åˆ†å— | å¤šæ ¼å¼ + æ™ºèƒ½æ£€ç´¢ |
| **å¯ç»´æŠ¤æ€§** | â­â­ | â­â­â­â­ | â­â­â­â­â­ |

### ROI åˆ†æ

| æŠ•å…¥ | äº§å‡º |
|------|------|
| **å¼€å‘æ—¶é—´**: 9-10 å¤© | **æ£€ç´¢å‡†ç¡®ç‡**: +31% |
| **ä»£ç é‡**: ~2000 è¡Œ | **ç”¨æˆ·ä½“éªŒ**: å¤§å¹…æå‡ï¼ˆå¼•ç”¨æ¥æºã€æ–‡æ¡£ç®¡ç†ï¼‰ |
| **ä¾èµ–å˜æ›´**: æ— æ–°å¢ | **å¯ç»´æŠ¤æ€§**: ä» 2 æ˜Ÿæå‡åˆ° 5 æ˜Ÿ |

---

## éªŒæ”¶æ ‡å‡†

### Level 1 éªŒæ”¶æ ‡å‡†

- [ ] æ‰€æœ‰æ–‡æ¡£éƒ½æœ‰å®Œæ•´å…ƒæ•°æ®ï¼ˆè‡³å°‘ 7 ä¸ªå­—æ®µï¼‰
- [ ] é•¿æ–‡æ¡£ï¼ˆ>500 å­—ï¼‰è¢«è‡ªåŠ¨åˆ†å—
- [ ] æ£€ç´¢å‚æ•°å¯é€šè¿‡é…ç½®æ–‡ä»¶åŠ¨æ€è°ƒæ•´
- [ ] æ”¯æŒæ–‡æ¡£å»é‡ï¼ˆåŸºäº content_hashï¼‰
- [ ] AI å›ç­”åŒ…å«å¼•ç”¨æ¥æºåˆ—è¡¨
- [ ] å¼•ç”¨æ¥æºæ˜¾ç¤ºæ–‡æ¡£ç‰‡æ®µå’Œç›¸ä¼¼åº¦åˆ†æ•°
- [ ] æ‰¹é‡å¯¼å…¥é€Ÿåº¦æå‡ 3-5 å€

### Level 2 éªŒæ”¶æ ‡å‡†

- [ ] ç”¨æˆ·æŸ¥è¯¢è¢«è‡ªåŠ¨æ”¹å†™ä¸ºæ›´æ¸…æ™°çš„å½¢å¼
- [ ] æ¯ä¸ªæŸ¥è¯¢ç”Ÿæˆ 2-3 ä¸ªè¯­ä¹‰å˜ä½“
- [ ] æ£€ç´¢ç»“æœæŒ‰ç›¸å…³æ€§é‡æ’åº
- [ ] æä¾›å®Œæ•´çš„æ–‡æ¡£ CRUD API
- [ ] æ”¯æŒæŒ‰å…ƒæ•°æ®è¿‡æ»¤æ£€ç´¢ï¼ˆsource, category, doc_typeï¼‰
- [ ] æ£€ç´¢å‡†ç¡®ç‡æå‡ 25% ä»¥ä¸Š
- [ ] æŸ¥è¯¢ä¼˜åŒ–æ€»è€—æ—¶ < 1s

---

## é£é™©ä¸æ³¨æ„äº‹é¡¹

### 1. æ€§èƒ½é£é™©

**é£é™©**: æŸ¥è¯¢é‡å†™ã€æŸ¥è¯¢æ‰©å±•ä¼šå¢åŠ å“åº”æ—¶é—´

**ç¼“è§£æªæ–½**:
- ä½¿ç”¨ä¾¿å®œå¿«é€Ÿçš„æ¨¡å‹ï¼ˆå¦‚ DeepSeekï¼‰è¿›è¡ŒæŸ¥è¯¢ä¼˜åŒ–
- æ·»åŠ æŸ¥è¯¢ç»“æœç¼“å­˜ï¼ˆRedisï¼‰ï¼Œå¯¹çƒ­é—¨æŸ¥è¯¢é¢„çƒ­
- æä¾›é…ç½®å¼€å…³ï¼Œå…è®¸æŒ‰éœ€å¯ç”¨/ç¦ç”¨

### 2. Token æ¶ˆè€—é£é™©

**é£é™©**: æŸ¥è¯¢ä¼˜åŒ–ä¼šé¢å¤–è°ƒç”¨ LLMï¼ˆå¢åŠ æˆæœ¬ï¼‰

**ç¼“è§£æªæ–½**:
- ä½¿ç”¨é…ç½®å¼€å…³ï¼Œä»…åœ¨å¿…è¦æ—¶å¯ç”¨
- ä½¿ç”¨ä¾¿å®œçš„æ¨¡å‹ï¼ˆå¦‚ DeepSeek: Â¥1/ç™¾ä¸‡ tokensï¼‰
- ç¼“å­˜æŸ¥è¯¢é‡å†™ç»“æœ

### 3. æ•°æ®è¿ç§»é£é™©

**é£é™©**: æ·»åŠ å…ƒæ•°æ®åï¼Œæ—§æ•°æ®æ²¡æœ‰å…ƒæ•°æ®

**ç¼“è§£æªæ–½**:
- ç¼–å†™æ•°æ®è¿ç§»è„šæœ¬ï¼Œä¸ºæ—§æ•°æ®è¡¥å……é»˜è®¤å…ƒæ•°æ®
- å…¼å®¹æ¨¡å¼ï¼šè¯»å–æ—¶æ£€æŸ¥å…ƒæ•°æ®æ˜¯å¦å­˜åœ¨ï¼Œç¼ºå¤±åˆ™å¡«å……é»˜è®¤å€¼

### 4. å…¼å®¹æ€§é£é™©

**é£é™©**: Spring AI 1.1.0 å¯èƒ½ä¸ Spring AI Alibaba 1.1.0.0-RC2 æœ‰å…¼å®¹æ€§é—®é¢˜

**ç¼“è§£æªæ–½**:
- åœ¨å¼€å‘ç¯å¢ƒå……åˆ†æµ‹è¯•
- æŸ¥çœ‹å®˜æ–¹æ–‡æ¡£çš„å…¼å®¹æ€§è¯´æ˜
- å¿…è¦æ—¶å‡çº§åˆ°ç¨³å®šç‰ˆæœ¬

### 5. Redis æ€§èƒ½é£é™©

**é£é™©**: ç»´æŠ¤æ–‡æ¡£ ID åˆ—è¡¨å¯èƒ½å½±å“ Redis æ€§èƒ½

**ç¼“è§£æªæ–½**:
- ä½¿ç”¨ Redis Set å­˜å‚¨ï¼ˆO(1) æŸ¥è¯¢ï¼‰
- å®šæœŸæ¸…ç†æ— æ•ˆçš„æ–‡æ¡£ ID
- è€ƒè™‘ä½¿ç”¨ç‹¬ç«‹çš„ Redis å®ä¾‹

---

## ä¸‹ä¸€æ­¥è¡ŒåŠ¨

### æ¨èè¡ŒåŠ¨è·¯å¾„

#### é€‰é¡¹ 1: ç«‹å³å¼€å§‹ï¼ˆæ¨èï¼‰

ä»æœ€ç®€å•ã€æœ€é«˜ä»·å€¼çš„ä»»åŠ¡å¼€å§‹ï¼š

1. **ä»»åŠ¡ 1.3**: åŠ¨æ€é…ç½®å‚æ•°ï¼ˆ0.5 å¤©ï¼‰
   - ç«‹å³è§æ•ˆï¼šé™ä½é˜ˆå€¼å³å¯æå‡å¬å›ç‡ 10-15%

2. **ä»»åŠ¡ 1.1**: æ·»åŠ æ–‡æ¡£å…ƒæ•°æ®ï¼ˆ0.5 å¤©ï¼‰
   - ä¸ºåç»­åŠŸèƒ½æ‰“åŸºç¡€

3. **ä»»åŠ¡ 1.2**: å®ç°æ–‡æ¡£åˆ†å—ï¼ˆ1 å¤©ï¼‰
   - æ˜¾è‘—æå‡é•¿æ–‡æ¡£å¤„ç†èƒ½åŠ›

#### é€‰é¡¹ 2: å…ˆåšæŠ€æœ¯éªŒè¯

åœ¨ç‹¬ç«‹åˆ†æ”¯éªŒè¯å…³é”®æŠ€æœ¯ï¼š

1. éªŒè¯ `TokenTextSplitter` åˆ†å—æ•ˆæœ
2. éªŒè¯ `RewriteQueryTransformer` æŸ¥è¯¢é‡å†™æ•ˆæœ
3. æµ‹è¯• Spring AI 1.1.0 ä¸ Spring AI Alibaba å…¼å®¹æ€§

#### é€‰é¡¹ 3: å…ˆå‡†å¤‡æ•°æ®è¿ç§»

å¦‚æœå·²æœ‰å¤§é‡ç”Ÿäº§æ•°æ®ï¼š

1. ç¼–å†™æ•°æ®è¿ç§»è„šæœ¬
2. ä¸ºæ—§æ•°æ®è¡¥å……å…ƒæ•°æ®
3. åœ¨æµ‹è¯•ç¯å¢ƒéªŒè¯

---

## é™„å½•

### A. ç›¸å…³æ–‡æ¡£é“¾æ¥

- [Spring AI å®˜æ–¹æ–‡æ¡£](https://docs.spring.io/spring-ai/reference/)
- [Spring AI Alibaba æ–‡æ¡£](https://github.com/alibaba/spring-ai-alibaba)
- [RAG æœ€ä½³å®è·µ](https://docs.spring.io/spring-ai/reference/api/retrieval-augmented-generation.html)
- [TokenTextSplitter æ–‡æ¡£](https://docs.spring.io/spring-ai/reference/api/etl-pipeline.html)

### B. è”ç³»æ–¹å¼

- **æŠ€æœ¯æ”¯æŒ**: xurx@example.com
- **é¡¹ç›®ä»“åº“**: [GitHub é“¾æ¥]
- **æ–‡æ¡£ç‰ˆæœ¬**: v1.0
- **æœ€åæ›´æ–°**: 2026-01-04

---

**ç¥å®æ–½é¡ºåˆ©ï¼** ğŸš€
